## Retours d'expérience
### REX d'une hydrologue

Une premiere difficulté que nous avons rencontré dans le déploiement d'un service STA de diffusion de nos données d'observatoire de recherche en environnement a été de passer du modèle théorique (les things, sensors, observedproperties, featuresofinterest) a son implémentation dans les realités que nous manipulons (les séries temporelles de variables, les points de mesures, les replicats de mesures). La première étape a ete de s'accorder sur ce que pouvait representer concretement une thing (un point de mesure, une variable sur une station...), une festure of interest, etc. Le modele Sensorthing reinterroge la nomenclature du "jeu de donnees", quand on fait de l'observation long-terme on en a une definition donnee par le couple variable et point de mesure (location X,Y,Z), si on doit changer un capteur, ou de laboratoire d'analyse ça reste le même jeu de donnees. Dans le modele SensorThings un jeu de données ou datastream est associe a un sensor unique. La définition de "Things" qu'on s'est donnée pour le déploiement d'un STA de l'observatoire AgrHyS, nous avons propose une definition un peu differente pour le service de donnees brutes et le service de donnees validees. Aussi, notre observatoire presente un historique de donnees considerable, avec beaucoup de fichiers de donnees historiques, des evolutions de pas de temps, des modifications de capteurs pour suivre les memes "caracteristiques d'interet", une partie des fichiers au format Excel, ou geres via des outils commerciaux non ouverts. 

Une autre difficulte est de se detacher de l'utilisation que nous avions prevue et qui a motive l'acquisition des données. Cela influence d'abord le choix de ce qu'on diffuse: la donnee brute ou la donnee traitee a laquelle on a apporté une expertise. La diffusion de la donnée brute est perçue par les thématiciens comme moins utilisable et parfois même dangereuse au regard d'utilisations inappropriées qui pourraient en être faites. La dimension transparante du fait de donner accès à la donnée brute est à première vue peu considérée comme une exigence. En revanche, la diffusion de la donnée brute est perçue comme plus engageante, plus exigente, sans doute parce que jusqu'ici les méthodes de validation et traitement font appel à une expertise et que la description standardisée de cette expertise est un défi. Les méthodes de traitement automatisées, perçues comme très objectives, peuvent sans doute être stimulées par la généralisation de standards interopérables. Cela influence aussi les thesaurus qu'on mobilise pour standardiser le vocabulaire des variables. Sans doute est-ce variable selon les communautés scientifiques et institutionnelles, selon la culture et le rapport entretenu à la mission de production de données. 

