## REX d'une hydrologue

### Qui parle ?
                    
![Ophelie Fovet](/img/ophelie.jpg) Ophélie Fovet, chargée de recherche INRAE, responsable de l'ORE AgrHyS, hydrologue.

### Le besoin

Créer un service numérique "SensorThings" pour la diffusion des données chimiques, physico-chimiques, hydrologiques et météorologiques produites depuis 1992 (?) dans le cadre de l'Observatoire de Recherche en Environnement (ORE) AgrHyS sur les sites de Naizin dans le Morbiban et Kerbernez à Plomelin dans le Finistère.

### Retour d'expérience

Une premiere difficulté que nous avons rencontré dans le déploiement d'un service SensorThings API (STA) de diffusion de nos données d'observatoire de recherche en environnement a été de passer du modèle théorique (les *things, sensors, observedproperties, featuresofinterest*) a son implémentation dans les realités que nous manipulons (les séries temporelles de variables, les points de mesures, les replicats de mesures). La première étape a été de s'accorder sur ce que pouvait représenter concrètement une *thing* (un point de mesure ?), une *observed property* (une variable sur une station ?), une *feature of interest* (un bassin versant ?), etc. Le modèle SensorThings réinterroge la nomenclature du "jeu de données", quand on fait de l'observation long-terme on en a une définition donnée par le couple variable et point de mesure (location X,Y,Z), si on doit changer un capteur, ou de laboratoire d'analyse ça reste le même jeu de données. Dans le modèle SensorThings, un jeu de données ou *datastream* est associé à un sensor unique. La définition de *Things* qu'on s'est donnée pour le déploiement d'un STA de l'observatoire AgrHyS, nous avons propose une définition un peu différente pour le service de données brutes et le service de données validées. Aussi, notre observatoire présente un historique de données considérable, avec beaucoup de fichiers de données historiques, des évolutions de pas de temps, des modifications de capteurs pour suivre les mêmes "caracteristiques d'interet", une partie des fichiers au format Excel, ou gérés via des outils commerciaux non ouverts. 

Une autre difficulté est de se détacher de l'utilisation que nous avions prévue et qui a motive l'acquisition des données. Cela influence d'abord le choix de ce qu'on diffuse: la donnée brute ou la donnée traitée a laquelle on a apporté une expertise. La diffusion de la donnée brute est perçue par les thématiciens comme moins utilisable et parfois même dangereuse au regard d'utilisations inappropriées qui pourraient en être faites. La dimension transparante du fait de donner accès à la donnée brute est à première vue peu considérée comme une exigence. En revanche, la diffusion de la donnée brute est perçue comme plus engageante, plus exigente, sans doute parce que jusqu'ici les méthodes de validation et traitement font appel à une expertise et que la description standardisée de cette expertise est un défi. Les méthodes de traitement automatisées, perçues comme très objectives, peuvent sans doute être stimulées par la généralisation de standards interopérables. Cela influence aussi les thesaurus qu'on mobilise pour standardiser le vocabulaire des variables. Sans doute est-ce variable selon les communautés scientifiques et institutionnelles, selon la culture et le rapport entretenu à la mission de production de données. 

